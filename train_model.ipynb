{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLsYQnZl-uJd",
        "colab_type": "code",
        "outputId": "141c7ae2-98a9-4446-c170-53ad22b9c2a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "import re\n",
        "import numpy as np\n",
        "\n",
        "!git clone https://github.com/IlyaSk10/stress_symbol_predict/\n",
        "%cd stress_symbol_predict\n",
        "!unzip train_dataset.zip\n",
        "\n",
        "# чтение словаря\n",
        "with open(\"All_Forms_1.txt\",'r',encoding='UTF-8') as f:\n",
        "  file=f.readlines()\n",
        "\n",
        "\n",
        "ret=[re.findall(r'[^,]+',re.sub(r'\\w+#','',i)) for i in file]   \n",
        "\n",
        "\n",
        "\n",
        "CHARS = ['-', 'а', 'б', 'в', 'г', 'д', 'е', 'ж', 'з', 'и', 'й', 'к',\n",
        "         'л', 'м', 'н', 'о', 'п', 'р', 'с', 'т', 'у', 'ф', 'х', 'ц', 'ч', 'ш',\n",
        "         'щ', 'ъ', 'ы', 'ь', 'э', 'ю', 'я', 'ё']\n",
        "CHAR_INDICES = dict((c, i+1) for i, c in enumerate(CHARS))\n",
        "\n",
        "\n",
        "# создание структуры \"слово:номер буквы на которую падает ударение\"\n",
        "df={}\n",
        "list2=[]\n",
        "words_without_stress=[]\n",
        "for string in ret:\n",
        "    for word in string:\n",
        "        if len(re.findall(r'(.+)\\'|(.+)\\`',word.strip()))>0:\n",
        "            #front=re.findall(r'(.+)\\'|(.+)\\`',word.strip())\n",
        "            front=re.sub(r'[\\`\\']','',re.findall(r'(.+)[\\`\\']',word.strip())[0])\n",
        "            clean_word=''.join(re.findall(r'[^\\'\\`]',word.strip()))\n",
        "            #df.update({clean_word:len(max(*front))})\n",
        "            df.update({clean_word:len(front)})\n",
        "    if len(df)>0:\n",
        "      list2.append(df.copy())\n",
        "      df.clear()\n",
        "    else:\n",
        "      words_without_stress.append(string)\n",
        "  \n",
        "print('Слова без разметки',words_without_stress[:20]) # слова без разметки и поэтому не учитываются далее\n",
        "\n",
        "#np.sum([len(list2[i]) for i in range(len(list2))])\n",
        "MAXLEN=max(len(word) for k in range(len(list2)) for word in list2[k].keys())\n",
        "print('Максимальная длина слова с разметкой', MAXLEN, 'символов')\n",
        "\n",
        "MAXLEN_WITHOUT_STRESS=max(len(word) for k in range(len(ret)) for word in ret[k])\n",
        "print('Максимальная длина слова без разметки', MAXLEN_WITHOUT_STRESS, 'символов')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'stress_symbol_predict'...\n",
            "remote: Enumerating objects: 97, done.\u001b[K\n",
            "remote: Total 97 (delta 0), reused 0 (delta 0), pack-reused 97\n",
            "Unpacking objects: 100% (97/97), done.\n",
            "/content/stress_symbol_predict\n",
            "Archive:  train_dataset.zip\n",
            "  inflating: All_Forms_1.txt         \n",
            "Слова без разметки [['\\ufeffа\\n'], ['абы\\n'], ['авансом\\n'], ['ага\\n'], ['агами\\n'], ['агу\\n'], ['адажио\\n'], ['адски\\n'], ['аж\\n'], ['азу\\n'], ['актёр', 'актёры', 'актёра', 'актёров', 'актёру', 'актёрам', 'актёра', 'актёров', 'актёром', 'актёрами', 'актёре', 'актёрах\\n'], ['актёришка', 'актёришки', 'актёришки', 'актёришек', 'актёришке', 'актёришкам', 'актёришку', 'актёришек', 'актёришкой', 'актёришкою', 'актёришками', 'актёришке', 'актёришках\\n'], ['актёрка', 'актёрки', 'актёрки', 'актёрок', 'актёрке', 'актёркам', 'актёрку', 'актёрок', 'актёркой', 'актёркою', 'актёрками', 'актёрке', 'актёрках\\n'], ['актёрство', 'актёрства', 'актёрства', 'актёрств', 'актёрству', 'актёрствам', 'актёрство', 'актёрства', 'актёрством', 'актёрствами', 'актёрстве', 'актёрствах\\n'], ['актёрствовать', 'актёрствую', 'актёрствуем', 'актёрствуешь', 'актёрствуете', 'актёрствует', 'актёрствуют', 'актёрствуя', 'актёрствовал', 'актёрствовала', 'актёрствовало', 'актёрствовали', 'актёрствуй', 'актёрствуйте', 'актёрствующий', 'актёрствующая', 'актёрствующее', 'актёрствующие', 'актёрствующего', 'актёрствующей', 'актёрствующего', 'актёрствующих', 'актёрствующему', 'актёрствующей', 'актёрствующему', 'актёрствующим', 'актёрствующий', 'актёрствующую', 'актёрствующее', 'актёрствующие', 'актёрствующего', 'актёрствующую', 'актёрствующее', 'актёрствующих', 'актёрствующим', 'актёрствующей', 'актёрствующею', 'актёрствующим', 'актёрствующими', 'актёрствующем', 'актёрствующей', 'актёрствующем', 'актёрствующих', 'актёрствовавший', 'актёрствовавшая', 'актёрствовавшее', 'актёрствовавшие', 'актёрствовавшего', 'актёрствовавшей', 'актёрствовавшего', 'актёрствовавших', 'актёрствовавшему', 'актёрствовавшей', 'актёрствовавшему', 'актёрствовавшим', 'актёрствовавший', 'актёрствовавшую', 'актёрствовавшее', 'актёрствовавшие', 'актёрствовавшего', 'актёрствовавшую', 'актёрствовавшее', 'актёрствовавших', 'актёрствовавшим', 'актёрствовавшей', 'актёрствовавшею', 'актёрствовавшим', 'актёрствовавшими', 'актёрствовавшем', 'актёрствовавшей', 'актёрствовавшем', 'актёрствовавших\\n'], ['акушёр', 'акушёры', 'акушёра', 'акушёров', 'акушёру', 'акушёрам', 'акушёра', 'акушёров', 'акушёром', 'акушёрами', 'акушёре', 'акушёрах\\n'], ['алегретто\\n'], ['алёнка', 'алёнки', 'алёнки', 'алёнок', 'алёнке', 'алёнкам', 'алёнку', 'алёнок', 'алёнкой', 'алёнкою', 'алёнками', 'алёнке', 'алёнках\\n'], ['алёхонький', 'алёхонькая', 'алёхонькое', 'алёхонькие', 'алёхонького', 'алёхонькой', 'алёхонького', 'алёхоньких', 'алёхонькому', 'алёхонькой', 'алёхонькому', 'алёхоньким', 'алёхонький', 'алёхонькую', 'алёхонькое', 'алёхонькие', 'алёхонького', 'алёхонькую', 'алёхонькое', 'алёхоньких', 'алёхоньким', 'алёхонькой', 'алёхонькою', 'алёхоньким', 'алёхонькими', 'алёхоньком', 'алёхонькой', 'алёхоньком', 'алёхоньких', 'алёхонек', 'алёхонька', 'алёхонько', 'алёхоньки\\n'], ['али\\n']]\n",
            "Максимальная длина слова с разметкой 31 символов\n",
            "Максимальная длина слова без разметки 33 символов\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "01dPlIRPTy7L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# функция преобразования каждого слова в набор чисел\n",
        "def preparation (list2):\n",
        "  total=np.sum([len(list2[i]) for i in range(len(list2))])\n",
        "  A=np.zeros(shape=(total,MAXLEN))\n",
        "  B=np.zeros(shape=(total,1))\n",
        "  m=0\n",
        "  for k in range(len(list2)):\n",
        "    for i in range(len(list2[k])):\n",
        "        x = np.zeros((1, MAXLEN)) \n",
        "        word=list(list2[k].keys())[i]\n",
        "        for index, letter in enumerate(word.strip()):\n",
        "            x[0,index]=CHAR_INDICES[letter] # слово представлено вектором чисел от 0 до 33\n",
        "        A[m,:]=x\n",
        "        B[m,:]=list2[k][word]\n",
        "        m=m+1\n",
        "  return A,B\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ts5GmI-E0fb9",
        "colab_type": "code",
        "outputId": "bba1e2ab-5c7a-4bcd-a391-328983dc62f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import random\n",
        "list_number_elements=20000\n",
        "random.shuffle(list2) # перемешиваем данные\n",
        "X_test,y_test=preparation(list2[:list_number_elements]) # и берем первые 20000 штук элементов списка. Каждый элемент списка это (слово+все словообразования)\n",
        "X_train,y_train=preparation(list2[list_number_elements:])\n",
        "\n",
        "from keras.utils.np_utils import to_categorical\n",
        "y_test_cat = to_categorical(y_test, num_classes=MAXLEN)\n",
        "y_train_cat = to_categorical(y_train, num_classes=MAXLEN)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c13Q0KkK9XX2",
        "colab_type": "code",
        "outputId": "bc751af3-c9a2-482e-8faf-3d35ca5eb983",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "#функция конвертирует вектор в слово\n",
        "def convert(X): \n",
        "  word_concat=[]\n",
        "  for word in X:\n",
        "    word_concat.append(''.join([key for index,number in enumerate(word) for key,value in CHAR_INDICES.items() if value==number]))\n",
        "  return word_concat\n",
        "\n",
        "w=list((key,value) for i in range(len(list2)) for key,value in list2[i].items())\n",
        "number=np.sum([len(list2[i]) for i in range(len(list2[:list_number_elements]))])\n",
        "\n",
        "number_of_words=20\n",
        "word_concat=convert(X_train[:number_of_words])\n",
        "\n",
        "for i in range(len(y_train_cat[:number_of_words])):\n",
        "  lab=np.argmax(y_train_cat[i])\n",
        "  print('Слово после конвертации :',word_concat[i][:lab]+\"'\"+word_concat[i][lab:],'|','Слово из словаря :',w[number+i][0][:w[number+i][1]]+\"'\"+w[number+i][0][w[number+i][1]:])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Слово после конвертации : де'ррик | Слово из словаря : де'ррик\n",
            "Слово после конвертации : де'ррики | Слово из словаря : де'ррики\n",
            "Слово после конвертации : де'ррика | Слово из словаря : де'ррика\n",
            "Слово после конвертации : де'рриков | Слово из словаря : де'рриков\n",
            "Слово после конвертации : де'ррику | Слово из словаря : де'ррику\n",
            "Слово после конвертации : де'ррикам | Слово из словаря : де'ррикам\n",
            "Слово после конвертации : де'рриком | Слово из словаря : де'рриком\n",
            "Слово после конвертации : де'рриками | Слово из словаря : де'рриками\n",
            "Слово после конвертации : де'ррике | Слово из словаря : де'ррике\n",
            "Слово после конвертации : де'рриках | Слово из словаря : де'рриках\n",
            "Слово после конвертации : обстре'лянный | Слово из словаря : обстре'лянный\n",
            "Слово после конвертации : обстре'лянная | Слово из словаря : обстре'лянная\n",
            "Слово после конвертации : обстре'лянное | Слово из словаря : обстре'лянное\n",
            "Слово после конвертации : обстре'лянные | Слово из словаря : обстре'лянные\n",
            "Слово после конвертации : обстре'лянного | Слово из словаря : обстре'лянного\n",
            "Слово после конвертации : обстре'лянной | Слово из словаря : обстре'лянной\n",
            "Слово после конвертации : обстре'лянных | Слово из словаря : обстре'лянных\n",
            "Слово после конвертации : обстре'лянному | Слово из словаря : обстре'лянному\n",
            "Слово после конвертации : обстре'лянным | Слово из словаря : обстре'лянным\n",
            "Слово после конвертации : обстре'лянную | Слово из словаря : обстре'лянную\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5FZ4-Z_C50N8",
        "colab_type": "code",
        "outputId": "5168c63f-7cb1-49c7-840e-9395de7adde2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        }
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation,Embedding,Bidirectional,LSTM\n",
        "\n",
        "# создание сети\n",
        "model = Sequential()\n",
        "vocab_size=len(X_train)\n",
        "model.add(Embedding(vocab_size, output_dim= len(CHARS), input_length=MAXLEN))\n",
        "model.add(Bidirectional(LSTM(units=64, input_shape=(MAXLEN, len(CHARS)),dropout = 0.2)))\n",
        "model.add(Dense(MAXLEN, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# обучение модели\n",
        "model.fit(X_train, y_train_cat, batch_size = 64,epochs=5,validation_data = (X_test, y_test_cat),verbose = 1)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 1163184 samples, validate on 364400 samples\n",
            "Epoch 1/5\n",
            "1163184/1163184 [==============================] - 3497s 3ms/step - loss: 0.7367 - accuracy: 0.7147 - val_loss: 0.5037 - val_accuracy: 0.8002\n",
            "Epoch 2/5\n",
            "1163184/1163184 [==============================] - 3488s 3ms/step - loss: 0.4300 - accuracy: 0.8289 - val_loss: 0.4181 - val_accuracy: 0.8408\n",
            "Epoch 3/5\n",
            "1163184/1163184 [==============================] - 3493s 3ms/step - loss: 0.3509 - accuracy: 0.8627 - val_loss: 0.3925 - val_accuracy: 0.8554\n",
            "Epoch 4/5\n",
            "1163184/1163184 [==============================] - 3503s 3ms/step - loss: 0.3059 - accuracy: 0.8817 - val_loss: 0.3593 - val_accuracy: 0.8692\n",
            "Epoch 5/5\n",
            "1163184/1163184 [==============================] - 3500s 3ms/step - loss: 0.2846 - accuracy: 0.8911 - val_loss: 0.3568 - val_accuracy: 0.8697\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f90acb83978>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-XBRJkZ0uND",
        "colab_type": "code",
        "outputId": "c2f12b26-5d41-48f5-d27f-bd05a79cd032",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def accuracy(X_test):\n",
        "  predicted=model.predict(X_test)\n",
        "  predicted = np.argmax(predicted, axis=1)\n",
        "  return accuracy_score(y_test, predicted)\n",
        "\n",
        "print('Доля правильных ответов','{:.3f}'.format(accuracy(X_test)))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Доля правильных ответов 0.870\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVxKcqzZfFPs",
        "colab_type": "code",
        "outputId": "1023c199-1ee2-4d10-bbac-e1df78924a0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "number_of_words=100 # возьмем первые 100 слов из test\n",
        "word_concat_test=convert(X_test[:number_of_words])\n",
        "\n",
        "correct_predict=[] # список для слов в которых верно проставлено ударение\n",
        "incorrect_predict=[] # список для слов в которых неверно проставлено ударение\n",
        "\n",
        "for i in range(len(X_test[:number_of_words])):\n",
        "  predicted=model.predict(X_test[i].reshape(1,MAXLEN))\n",
        "  predicted = np.argmax(predicted, axis=1)\n",
        "  if y_test[i]==predicted:\n",
        "    correct_predict.append(word_concat_test[i][:int(predicted)]+\"'\"+word_concat_test[i][int(predicted):])\n",
        "  else:\n",
        "    incorrect_predict.append(word_concat_test[i][:int(predicted)]+\"'\"+word_concat_test[i][int(predicted):])\n",
        "\n",
        "print([('Правильный ответ :',word_correct) for word_correct in correct_predict])\n",
        "print([('Неправильный ответ :',word_incorrect) for word_incorrect in incorrect_predict])"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('Правильный ответ :', \"рассолоди'ть\"), ('Правильный ответ :', \"рассоложу'\"), ('Правильный ответ :', \"рассолоди'м\"), ('Правильный ответ :', \"рассолоди'те\"), ('Правильный ответ :', \"рассолоди'т\"), ('Правильный ответ :', \"рассолодя'\"), ('Правильный ответ :', \"рассолоди'л\"), ('Правильный ответ :', \"рассолоди'ла\"), ('Правильный ответ :', \"рассолоди'ло\"), ('Правильный ответ :', \"рассолоди'ли\"), ('Правильный ответ :', \"рассолоди'\"), ('Правильный ответ :', \"рассолоди'вший\"), ('Правильный ответ :', \"рассолоди'вшая\"), ('Правильный ответ :', \"рассолоди'вшее\"), ('Правильный ответ :', \"рассолоди'вшие\"), ('Правильный ответ :', \"рассолоди'вшего\"), ('Правильный ответ :', \"рассолоди'вшей\"), ('Правильный ответ :', \"рассолоди'вших\"), ('Правильный ответ :', \"рассолоди'вшему\"), ('Правильный ответ :', \"рассолоди'вшим\"), ('Правильный ответ :', \"рассолоди'вшую\"), ('Правильный ответ :', \"рассолоди'вшею\"), ('Правильный ответ :', \"рассолоди'вшими\"), ('Правильный ответ :', \"рассолоди'вшем\"), ('Правильный ответ :', \"переупако'вки\"), ('Правильный ответ :', \"переупако'вок\"), ('Правильный ответ :', \"переупако'вке\"), ('Правильный ответ :', \"переупако'вку\"), ('Правильный ответ :', \"переупако'вкою\"), ('Правильный ответ :', \"переупако'вках\"), ('Правильный ответ :', \"скра'сть\"), ('Правильный ответ :', \"скрадя'\"), ('Правильный ответ :', \"скра'л\"), ('Правильный ответ :', \"скра'ла\"), ('Правильный ответ :', \"скра'ло\"), ('Правильный ответ :', \"скра'ли\"), ('Правильный ответ :', \"скради'\"), ('Правильный ответ :', \"скради'те\"), ('Правильный ответ :', \"скра'вший\"), ('Правильный ответ :', \"скра'вшая\"), ('Правильный ответ :', \"скра'вшее\"), ('Правильный ответ :', \"скра'вшие\"), ('Правильный ответ :', \"скра'вшего\"), ('Правильный ответ :', \"скра'вшей\"), ('Правильный ответ :', \"скра'вших\"), ('Правильный ответ :', \"скра'вшему\"), ('Правильный ответ :', \"скра'вшим\"), ('Правильный ответ :', \"скра'вшую\"), ('Правильный ответ :', \"скра'вшею\"), ('Правильный ответ :', \"скра'вшими\"), ('Правильный ответ :', \"скра'вшем\"), ('Правильный ответ :', \"скра'денный\"), ('Правильный ответ :', \"скра'денная\"), ('Правильный ответ :', \"скра'денное\"), ('Правильный ответ :', \"скра'денные\"), ('Правильный ответ :', \"скра'денного\"), ('Правильный ответ :', \"скра'денной\"), ('Правильный ответ :', \"скра'денных\"), ('Правильный ответ :', \"скра'денному\"), ('Правильный ответ :', \"скра'денным\"), ('Правильный ответ :', \"скра'денную\"), ('Правильный ответ :', \"скра'денною\"), ('Правильный ответ :', \"скра'денными\"), ('Правильный ответ :', \"скра'денном\"), ('Правильный ответ :', \"скра'ден\"), ('Правильный ответ :', \"скра'дена\"), ('Правильный ответ :', \"скра'дено\"), ('Правильный ответ :', \"скра'дены\"), ('Правильный ответ :', \"трюка'чество\"), ('Правильный ответ :', \"трюка'чества\"), ('Правильный ответ :', \"трюка'честв\"), ('Правильный ответ :', \"трюка'честву\"), ('Правильный ответ :', \"трюка'чествам\"), ('Правильный ответ :', \"трюка'чеством\"), ('Правильный ответ :', \"трюка'чествами\"), ('Правильный ответ :', \"трюка'честве\"), ('Правильный ответ :', \"трюка'чествах\"), ('Правильный ответ :', \"незна'ние\"), ('Правильный ответ :', \"незна'ния\")]\n",
            "[('Неправильный ответ :', \"рассоло'дишь\"), ('Неправильный ответ :', \"рассоло'дят\"), ('Неправильный ответ :', \"рассоло'жена\"), ('Неправильный ответ :', \"рассоло'жено\"), ('Неправильный ответ :', \"рассоло'жены\"), ('Неправильный ответ :', \"переупа'ковка\"), ('Неправильный ответ :', \"переупа'ковкам\"), ('Неправильный ответ :', \"переупа'ковкой\"), ('Неправильный ответ :', \"переупа'ковками\"), ('Неправильный ответ :', \"скра'ду\"), ('Неправильный ответ :', \"скра'дут\"), ('Неправильный ответ :', \"корпуску'ла\"), ('Неправильный ответ :', \"корпуску'лы\"), ('Неправильный ответ :', \"корпуску'л\"), ('Неправильный ответ :', \"корпуску'ле\"), ('Неправильный ответ :', \"корпуску'лам\"), ('Неправильный ответ :', \"корпуску'лу\"), ('Неправильный ответ :', \"корпуску'лой\"), ('Неправильный ответ :', \"корпуску'лою\"), ('Неправильный ответ :', \"корпуску'лами\"), ('Неправильный ответ :', \"корпуску'лах\")]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7VsIP-Sl011f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "16ba726c-d1d1-4ed1-d67e-4e67b5a08b60"
      },
      "source": [
        "path='/content/drive'\n",
        "# сохранение модели и весов\n",
        "model_json = model.to_json()\n",
        "with open(path+\"model_3.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "model.save_weights(path+\"model_3.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}